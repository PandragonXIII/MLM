/home/xuyue/miniconda3/envs/llava/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/xuyue/miniconda3/envs/llava/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
processing images... denoise batch:   0%|          | 0/5 [00:00<?, ?it/s]denoise batch:  20%|██        | 1/5 [00:44<02:59, 44.89s/it]denoise batch:  40%|████      | 2/5 [01:28<02:13, 44.35s/it]denoise batch:  60%|██████    | 3/5 [02:12<01:28, 44.10s/it]denoise batch:  80%|████████  | 4/5 [02:56<00:44, 44.02s/it]denoise batch: 100%|██████████| 5/5 [03:06<00:00, 31.66s/it]denoise batch: 100%|██████████| 5/5 [03:06<00:00, 37.26s/it]
/home/xuyue/.local/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Done
computing cossim... Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.17it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.94it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.86it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.41it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
csv file saved at: ./temp_blip
Done
Defender initialized with threshold=-0.003936767578125
processed 218 images, 218 texts in 338.38s
using blip for generation
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.16s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.26s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.33s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.53s/it]
generating response:   0%|          | 0/218 [00:00<?, ?it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   0%|          | 1/218 [00:00<02:19,  1.56it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|          | 2/218 [00:00<01:38,  2.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|▏         | 3/218 [00:01<01:30,  2.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 4/218 [00:01<01:38,  2.17it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 5/218 [00:02<01:42,  2.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 6/218 [00:03<01:52,  1.88it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 7/218 [00:03<01:34,  2.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▎         | 8/218 [00:05<03:04,  1.14it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▍         | 9/218 [00:06<03:07,  1.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▍         | 10/218 [00:06<02:35,  1.33it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▌         | 11/218 [00:09<05:19,  1.54s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 12/218 [00:11<05:12,  1.52s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 13/218 [00:12<04:52,  1.42s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▋         | 14/218 [00:12<03:52,  1.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 15/218 [00:13<03:10,  1.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 16/218 [00:14<03:17,  1.02it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 17/218 [00:15<03:10,  1.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 18/218 [00:16<03:02,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▊         | 19/218 [00:16<02:36,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▉         | 20/218 [00:17<02:11,  1.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|▉         | 21/218 [00:20<05:00,  1.53s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|█         | 22/218 [00:21<04:23,  1.34s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 23/218 [00:22<03:57,  1.22s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 24/218 [00:22<03:10,  1.02it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█▏        | 25/218 [00:23<02:26,  1.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 26/218 [00:23<02:04,  1.54it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 27/218 [00:23<01:45,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 28/218 [00:24<01:52,  1.69it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 29/218 [00:25<02:35,  1.21it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 30/218 [00:26<02:37,  1.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 31/218 [00:27<02:03,  1.51it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▍        | 32/218 [00:27<01:39,  1.88it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▌        | 33/218 [00:32<06:28,  2.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 34/218 [00:38<09:10,  2.99s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 35/218 [00:44<12:37,  4.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 36/218 [00:45<09:48,  3.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 37/218 [00:50<11:07,  3.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 38/218 [00:54<11:03,  3.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 39/218 [00:54<07:56,  2.66s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 40/218 [00:55<05:53,  1.99s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 41/218 [00:55<04:26,  1.50s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 42/218 [00:55<03:22,  1.15s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|█▉        | 43/218 [00:56<02:43,  1.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|██        | 44/218 [00:56<02:16,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 45/218 [00:56<01:51,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 46/218 [01:23<23:40,  8.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 47/218 [01:23<16:53,  5.93s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 48/218 [01:24<12:28,  4.40s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 49/218 [01:24<08:52,  3.15s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 50/218 [01:25<07:20,  2.62s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 51/218 [01:26<05:25,  1.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 52/218 [01:26<04:02,  1.46s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 53/218 [01:27<03:05,  1.12s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▍       | 54/218 [01:27<02:20,  1.17it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▌       | 55/218 [01:27<01:54,  1.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 56/218 [01:28<01:52,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 57/218 [01:28<01:48,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 58/218 [01:29<01:47,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 59/218 [01:29<01:28,  1.79it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 60/218 [01:30<01:27,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 61/218 [01:30<01:13,  2.14it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 62/218 [01:30<01:04,  2.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 63/218 [01:31<00:59,  2.59it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 64/218 [01:34<02:48,  1.09s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|██▉       | 65/218 [01:34<02:17,  1.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|███       | 66/218 [01:34<01:53,  1.34it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 67/218 [01:35<01:33,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 68/218 [01:35<01:19,  1.88it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 69/218 [01:35<01:05,  2.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 70/218 [01:36<01:31,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 71/218 [01:37<01:16,  1.93it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 72/218 [01:37<01:09,  2.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 73/218 [01:37<01:04,  2.25it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 74/218 [01:38<00:59,  2.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 75/218 [01:38<00:57,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▍      | 76/218 [01:38<00:56,  2.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▌      | 77/218 [01:39<00:57,  2.47it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 78/218 [01:39<00:51,  2.70it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 79/218 [01:39<00:52,  2.64it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 80/218 [01:40<01:10,  1.96it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 81/218 [01:41<01:00,  2.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 82/218 [01:41<00:59,  2.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 83/218 [01:41<00:56,  2.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▊      | 84/218 [01:42<00:54,  2.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 85/218 [01:42<00:54,  2.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 86/218 [01:43<01:00,  2.17it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|███▉      | 87/218 [01:43<01:10,  1.86it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|████      | 88/218 [01:44<01:18,  1.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████      | 89/218 [02:10<17:39,  8.21s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████▏     | 90/218 [02:14<14:56,  7.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 91/218 [02:16<11:11,  5.28s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 92/218 [02:42<24:09, 11.51s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 93/218 [02:43<17:53,  8.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 94/218 [02:45<13:07,  6.35s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▎     | 95/218 [02:45<09:19,  4.55s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 96/218 [02:45<06:44,  3.31s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 97/218 [02:47<05:25,  2.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▍     | 98/218 [02:47<04:14,  2.12s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▌     | 99/218 [02:48<03:04,  1.55s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▌     | 100/218 [02:48<02:21,  1.20s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▋     | 101/218 [02:48<01:49,  1.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 102/218 [02:49<01:25,  1.35it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 103/218 [02:49<01:19,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 104/218 [02:51<01:47,  1.06it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 105/218 [02:56<04:04,  2.16s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▊     | 106/218 [02:56<03:00,  1.61s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▉     | 107/218 [02:56<02:12,  1.20s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|████▉     | 108/218 [02:57<01:51,  1.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 109/218 [02:58<01:39,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 110/218 [02:58<01:30,  1.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████     | 111/218 [02:59<01:14,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████▏    | 112/218 [03:00<01:21,  1.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 113/218 [03:00<01:03,  1.64it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 114/218 [03:01<01:27,  1.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 115/218 [03:01<01:09,  1.47it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 116/218 [03:02<00:55,  1.84it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▎    | 117/218 [03:02<00:46,  2.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▍    | 118/218 [03:02<00:39,  2.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▍    | 119/218 [03:03<00:44,  2.21it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▌    | 120/218 [03:03<00:49,  1.98it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 121/218 [03:04<00:41,  2.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 122/218 [03:05<01:09,  1.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▋    | 123/218 [03:06<01:13,  1.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 124/218 [03:06<00:57,  1.64it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 125/218 [03:06<00:46,  2.02it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 126/218 [03:07<00:55,  1.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 127/218 [03:09<01:26,  1.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▊    | 128/218 [03:09<01:08,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▉    | 129/218 [03:10<00:53,  1.68it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|█████▉    | 130/218 [03:10<00:44,  1.96it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|██████    | 131/218 [03:11<00:53,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 132/218 [03:12<00:59,  1.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 133/218 [03:12<00:58,  1.46it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████▏   | 134/218 [03:16<02:22,  1.70s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 135/218 [03:17<02:05,  1.51s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 136/218 [03:18<01:32,  1.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 137/218 [03:18<01:09,  1.17it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 138/218 [03:18<00:53,  1.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 139/218 [03:18<00:42,  1.87it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 140/218 [03:19<00:35,  2.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▍   | 141/218 [03:19<00:30,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▌   | 142/218 [03:19<00:26,  2.87it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 143/218 [03:19<00:23,  3.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 144/218 [03:20<00:22,  3.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 145/218 [03:20<00:23,  3.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 146/218 [03:20<00:21,  3.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 147/218 [03:20<00:19,  3.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 148/218 [03:21<00:20,  3.46it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 149/218 [03:23<01:01,  1.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 150/218 [03:24<00:52,  1.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 151/218 [03:27<01:43,  1.54s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|██████▉   | 152/218 [03:34<03:37,  3.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|███████   | 153/218 [03:35<02:39,  2.45s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 154/218 [03:35<01:57,  1.83s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 155/218 [03:38<02:24,  2.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 156/218 [03:39<01:46,  1.72s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 157/218 [03:44<02:45,  2.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 158/218 [03:48<03:02,  3.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 159/218 [03:51<03:12,  3.25s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 160/218 [03:52<02:16,  2.35s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 161/218 [03:52<01:43,  1.81s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 162/218 [03:53<01:15,  1.35s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▍  | 163/218 [03:56<01:51,  2.02s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▌  | 164/218 [04:00<02:14,  2.49s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 165/218 [04:00<01:44,  1.97s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 166/218 [04:01<01:24,  1.63s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 167/218 [04:07<02:21,  2.77s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 168/218 [04:07<01:40,  2.02s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 169/218 [04:12<02:17,  2.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 170/218 [04:18<03:11,  3.99s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 171/218 [04:25<03:41,  4.72s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 172/218 [04:31<03:53,  5.08s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 173/218 [04:36<03:52,  5.16s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|███████▉  | 174/218 [04:44<04:25,  6.03s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|████████  | 175/218 [04:50<04:13,  5.91s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 176/218 [04:58<04:33,  6.51s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 177/218 [05:05<04:37,  6.78s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 178/218 [05:13<04:45,  7.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 179/218 [05:15<03:41,  5.67s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 180/218 [05:21<03:40,  5.79s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 181/218 [05:25<03:11,  5.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 182/218 [05:29<02:49,  4.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 183/218 [05:32<02:30,  4.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 184/218 [05:35<02:17,  4.04s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▍ | 185/218 [05:39<02:09,  3.93s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▌ | 186/218 [05:42<01:56,  3.65s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 187/218 [05:45<01:49,  3.54s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 188/218 [05:49<01:49,  3.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 189/218 [05:50<01:17,  2.66s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 190/218 [05:50<00:54,  1.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 191/218 [05:50<00:38,  1.43s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 192/218 [05:50<00:28,  1.09s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▊ | 193/218 [05:51<00:21,  1.16it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 194/218 [05:51<00:16,  1.46it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 195/218 [05:51<00:13,  1.73it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|████████▉ | 196/218 [05:52<00:10,  2.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|█████████ | 197/218 [05:52<00:10,  2.06it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████ | 198/218 [05:53<00:08,  2.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████▏| 199/218 [05:53<00:07,  2.68it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 200/218 [05:56<00:24,  1.35s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 201/218 [05:58<00:22,  1.32s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 202/218 [05:59<00:19,  1.25s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 203/218 [06:00<00:17,  1.18s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▎| 204/218 [06:02<00:20,  1.50s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 205/218 [06:08<00:36,  2.82s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 206/218 [06:08<00:25,  2.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▍| 207/218 [06:12<00:27,  2.52s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▌| 208/218 [06:12<00:18,  1.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▌| 209/218 [06:12<00:12,  1.37s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▋| 210/218 [06:20<00:25,  3.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 211/218 [06:29<00:35,  5.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 212/218 [06:55<01:08, 11.35s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 213/218 [07:18<01:13, 14.65s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 214/218 [07:36<01:03, 15.76s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▊| 215/218 [07:52<00:47, 15.83s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▉| 216/218 [08:08<00:32, 16.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|█████████▉| 217/218 [08:16<00:13, 13.63s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|██████████| 218/218 [08:29<00:00, 13.15s/it]generating response: 100%|██████████| 218/218 [08:29<00:00,  2.33s/it]
generation part takes 540.06s
processing images... denoise batch:   0%|          | 0/5 [00:00<?, ?it/s]denoise batch:  20%|██        | 1/5 [00:43<02:54, 43.65s/it]denoise batch:  40%|████      | 2/5 [01:27<02:11, 43.85s/it]denoise batch:  60%|██████    | 3/5 [02:11<01:27, 43.96s/it]denoise batch:  80%|████████  | 4/5 [02:55<00:43, 43.98s/it]denoise batch: 100%|██████████| 5/5 [03:05<00:00, 31.57s/it]denoise batch: 100%|██████████| 5/5 [03:05<00:00, 37.06s/it]
/home/xuyue/.local/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Done
computing cossim... Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.19it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  4.06it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.92it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.51it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
csv file saved at: ./temp_blip
Done
Defender initialized with threshold=-0.003936767578125
processed 218 images, 218 texts in 1194.95s
using blip for generation
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.54s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.77s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.31s/it]
generating response:   0%|          | 0/218 [00:00<?, ?it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   0%|          | 1/218 [00:00<00:53,  4.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|          | 2/218 [00:00<01:03,  3.41it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|▏         | 3/218 [00:00<01:11,  3.03it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 4/218 [00:01<01:26,  2.46it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 5/218 [00:01<01:35,  2.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 6/218 [00:02<01:47,  1.97it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 7/218 [00:02<01:31,  2.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▎         | 8/218 [00:04<03:02,  1.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▍         | 9/218 [00:05<03:06,  1.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▍         | 10/218 [00:06<02:38,  1.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▌         | 11/218 [00:09<05:33,  1.61s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 12/218 [00:11<05:22,  1.56s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 13/218 [00:12<04:58,  1.46s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▋         | 14/218 [00:12<03:56,  1.16s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 15/218 [00:13<03:13,  1.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 16/218 [00:14<03:19,  1.01it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 17/218 [00:15<03:12,  1.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 18/218 [00:16<03:03,  1.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▊         | 19/218 [00:16<02:36,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▉         | 20/218 [00:16<02:11,  1.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|▉         | 21/218 [00:20<04:40,  1.42s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|█         | 22/218 [00:20<03:31,  1.08s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 23/218 [00:20<02:43,  1.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 24/218 [00:21<02:19,  1.39it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█▏        | 25/218 [00:21<01:51,  1.74it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 26/218 [00:22<02:15,  1.41it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 27/218 [00:22<01:53,  1.69it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 28/218 [00:23<01:58,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 29/218 [00:24<02:39,  1.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 30/218 [00:25<02:40,  1.17it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 31/218 [00:25<02:05,  1.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▍        | 32/218 [00:26<01:40,  1.85it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▌        | 33/218 [00:31<06:28,  2.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 34/218 [00:36<08:21,  2.72s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 35/218 [00:42<12:03,  3.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 36/218 [00:43<09:24,  3.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 37/218 [00:48<10:51,  3.60s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 38/218 [00:53<11:28,  3.83s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 39/218 [00:53<08:14,  2.76s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 40/218 [00:53<06:06,  2.06s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 41/218 [00:54<04:35,  1.55s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 42/218 [00:54<03:29,  1.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|█▉        | 43/218 [00:54<02:48,  1.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|██        | 44/218 [00:55<02:19,  1.25it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 45/218 [00:55<01:54,  1.52it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 46/218 [00:57<02:32,  1.13it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 47/218 [00:57<02:11,  1.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 48/218 [00:58<02:14,  1.26it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 49/218 [00:58<01:48,  1.56it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 50/218 [01:00<02:27,  1.14it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 51/218 [01:00<02:02,  1.37it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 52/218 [01:00<01:39,  1.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 53/218 [01:01<01:26,  1.91it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▍       | 54/218 [01:01<01:11,  2.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▌       | 55/218 [01:01<01:06,  2.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 56/218 [01:02<01:19,  2.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 57/218 [01:03<01:25,  1.87it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 58/218 [01:03<01:32,  1.73it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 59/218 [01:04<01:17,  2.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 60/218 [01:04<01:19,  1.99it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 61/218 [01:04<01:08,  2.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 62/218 [01:05<01:01,  2.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 63/218 [01:05<00:53,  2.92it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 64/218 [01:05<00:51,  2.97it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|██▉       | 65/218 [01:06<00:56,  2.70it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|███       | 66/218 [01:06<00:57,  2.66it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 67/218 [01:06<00:54,  2.77it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 68/218 [01:07<00:52,  2.84it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 69/218 [01:07<00:46,  3.18it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 70/218 [01:08<01:18,  1.88it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 71/218 [01:08<01:07,  2.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 72/218 [01:09<01:03,  2.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 73/218 [01:09<01:00,  2.41it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 74/218 [01:09<00:56,  2.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 75/218 [01:10<00:55,  2.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▍      | 76/218 [01:10<00:54,  2.59it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▌      | 77/218 [01:10<00:56,  2.51it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 78/218 [01:11<00:51,  2.74it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 79/218 [01:11<00:52,  2.66it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 80/218 [01:12<01:10,  1.97it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 81/218 [01:12<01:00,  2.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 82/218 [01:13<00:59,  2.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 83/218 [01:13<00:56,  2.39it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▊      | 84/218 [01:13<00:54,  2.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 85/218 [01:14<00:54,  2.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 86/218 [01:14<01:00,  2.18it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|███▉      | 87/218 [01:15<01:10,  1.86it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|████      | 88/218 [01:16<01:17,  1.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████      | 89/218 [01:19<02:44,  1.27s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████▏     | 90/218 [01:23<04:34,  2.15s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 91/218 [01:24<03:59,  1.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 92/218 [01:50<19:09,  9.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 93/218 [01:52<14:25,  6.92s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 94/218 [01:53<10:42,  5.18s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▎     | 95/218 [01:53<07:34,  3.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 96/218 [01:54<05:31,  2.72s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 97/218 [01:55<04:34,  2.27s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▍     | 98/218 [01:56<04:01,  2.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▌     | 99/218 [01:57<02:55,  1.48s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▌     | 100/218 [01:57<02:15,  1.15s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▋     | 101/218 [01:57<01:45,  1.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 102/218 [01:58<01:22,  1.41it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 103/218 [01:58<01:17,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 104/218 [02:00<01:45,  1.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 105/218 [02:05<04:02,  2.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▊     | 106/218 [02:05<02:59,  1.60s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▉     | 107/218 [02:05<02:11,  1.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|████▉     | 108/218 [02:06<01:50,  1.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 109/218 [02:07<01:38,  1.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 110/218 [02:07<01:25,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████     | 111/218 [02:07<01:09,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████▏    | 112/218 [02:08<00:55,  1.92it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 113/218 [02:08<00:45,  2.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 114/218 [02:08<00:50,  2.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 115/218 [02:09<00:43,  2.35it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 116/218 [02:09<00:37,  2.73it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▎    | 117/218 [02:09<00:34,  2.96it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▍    | 118/218 [02:09<00:30,  3.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▍    | 119/218 [02:10<00:38,  2.57it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▌    | 120/218 [02:11<00:44,  2.18it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 121/218 [02:11<00:38,  2.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 122/218 [02:12<01:07,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▋    | 123/218 [02:13<01:12,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 124/218 [02:13<00:56,  1.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 125/218 [02:15<01:10,  1.33it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 126/218 [02:16<01:39,  1.08s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 127/218 [02:18<01:57,  1.29s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▊    | 128/218 [02:18<01:28,  1.01it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▉    | 129/218 [02:19<01:07,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|█████▉    | 130/218 [02:19<00:54,  1.60it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|██████    | 131/218 [02:20<01:01,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 132/218 [02:21<01:04,  1.33it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 133/218 [02:21<01:01,  1.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████▏   | 134/218 [02:25<02:06,  1.51s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 135/218 [02:26<01:54,  1.38s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 136/218 [02:26<01:24,  1.03s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 137/218 [02:26<01:05,  1.24it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 138/218 [02:27<00:50,  1.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 139/218 [02:27<00:41,  1.90it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 140/218 [02:27<00:35,  2.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▍   | 141/218 [02:27<00:30,  2.52it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▌   | 142/218 [02:28<00:26,  2.89it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 143/218 [02:28<00:23,  3.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 144/218 [02:28<00:22,  3.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 145/218 [02:28<00:22,  3.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 146/218 [02:29<00:20,  3.51it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 147/218 [02:29<00:18,  3.75it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 148/218 [02:29<00:19,  3.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 149/218 [02:32<01:01,  1.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 150/218 [02:32<00:52,  1.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 151/218 [02:41<03:41,  3.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|██████▉   | 152/218 [02:42<02:53,  2.63s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|███████   | 153/218 [03:08<10:26,  9.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 154/218 [03:09<07:19,  6.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 155/218 [03:13<06:18,  6.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 156/218 [03:13<04:27,  4.32s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 157/218 [03:18<04:36,  4.53s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 158/218 [03:23<04:37,  4.62s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 159/218 [03:27<04:16,  4.36s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 160/218 [03:27<03:05,  3.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 161/218 [03:30<03:00,  3.16s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 162/218 [03:30<02:08,  2.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▍  | 163/218 [03:33<02:05,  2.28s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▌  | 164/218 [03:37<02:27,  2.73s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 165/218 [03:38<01:59,  2.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 166/218 [03:38<01:35,  1.83s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 167/218 [03:44<02:28,  2.91s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 168/218 [03:45<02:02,  2.46s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 169/218 [03:52<02:55,  3.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 170/218 [03:57<03:18,  4.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 171/218 [04:02<03:30,  4.49s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 172/218 [04:08<03:39,  4.78s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 173/218 [04:15<04:02,  5.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|███████▉  | 174/218 [04:22<04:25,  6.04s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|████████  | 175/218 [04:28<04:11,  5.85s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 176/218 [04:34<04:09,  5.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 177/218 [04:40<04:11,  6.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 178/218 [04:47<04:13,  6.34s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 179/218 [04:51<03:43,  5.73s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 180/218 [04:57<03:41,  5.84s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 181/218 [05:01<03:12,  5.21s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 182/218 [05:03<02:25,  4.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 183/218 [05:06<02:14,  3.84s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 184/218 [05:10<02:10,  3.84s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▍ | 185/218 [05:14<02:11,  4.00s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▌ | 186/218 [05:18<02:04,  3.89s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 187/218 [05:22<02:00,  3.87s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 188/218 [05:24<01:41,  3.37s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 189/218 [05:24<01:11,  2.46s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 190/218 [05:24<00:50,  1.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 191/218 [05:25<00:35,  1.33s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 192/218 [05:25<00:26,  1.02s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▊ | 193/218 [05:25<00:20,  1.24it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 194/218 [05:25<00:15,  1.54it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 195/218 [05:26<00:12,  1.81it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|████████▉ | 196/218 [05:26<00:10,  2.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|█████████ | 197/218 [05:27<00:09,  2.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████ | 198/218 [05:27<00:08,  2.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████▏| 199/218 [05:27<00:07,  2.71it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 200/218 [05:31<00:23,  1.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 201/218 [05:31<00:18,  1.07s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 202/218 [05:32<00:17,  1.07s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 203/218 [05:33<00:15,  1.06s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▎| 204/218 [05:35<00:19,  1.41s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 205/218 [05:38<00:21,  1.65s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 206/218 [05:38<00:15,  1.29s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▍| 207/218 [05:42<00:21,  1.94s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▌| 208/218 [05:42<00:14,  1.46s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▌| 209/218 [05:42<00:09,  1.08s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▋| 210/218 [05:50<00:24,  3.03s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 211/218 [05:59<00:34,  4.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 212/218 [06:25<01:07, 11.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 213/218 [06:47<01:12, 14.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 214/218 [07:07<01:04, 16.12s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▊| 215/218 [07:23<00:48, 16.08s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▉| 216/218 [07:43<00:34, 17.24s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|█████████▉| 217/218 [07:51<00:14, 14.49s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|██████████| 218/218 [08:03<00:00, 13.76s/it]generating response: 100%|██████████| 218/218 [08:03<00:00,  2.22s/it]
generation part takes 502.82s
processing images... denoise batch:   0%|          | 0/5 [00:00<?, ?it/s]denoise batch:  20%|██        | 1/5 [00:43<02:53, 43.43s/it]denoise batch:  40%|████      | 2/5 [01:27<02:11, 43.77s/it]denoise batch:  60%|██████    | 3/5 [02:11<01:27, 43.92s/it]denoise batch:  80%|████████  | 4/5 [02:55<00:44, 44.01s/it]denoise batch: 100%|██████████| 5/5 [03:05<00:00, 31.59s/it]denoise batch: 100%|██████████| 5/5 [03:05<00:00, 37.05s/it]
/home/xuyue/.local/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Done
computing cossim... Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  4.55it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  5.63it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  6.20it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  5.88it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
csv file saved at: ./temp_blip
Done
Defender initialized with threshold=-0.003936767578125
processed 218 images, 218 texts in 1990.87s
using blip for generation
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:04,  2.06s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.89s/it]
generating response:   0%|          | 0/218 [00:00<?, ?it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   0%|          | 1/218 [00:00<00:58,  3.69it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|          | 2/218 [00:00<01:05,  3.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|▏         | 3/218 [00:00<01:12,  2.98it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 4/218 [00:01<01:27,  2.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 5/218 [00:02<01:35,  2.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 6/218 [00:02<01:47,  1.96it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 7/218 [00:02<01:31,  2.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▎         | 8/218 [00:04<03:02,  1.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▍         | 9/218 [00:05<03:05,  1.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▍         | 10/218 [00:06<02:38,  1.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▌         | 11/218 [00:09<05:20,  1.55s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 12/218 [00:10<05:13,  1.52s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 13/218 [00:12<04:46,  1.40s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▋         | 14/218 [00:12<03:48,  1.12s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 15/218 [00:12<03:07,  1.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 16/218 [00:14<03:15,  1.03it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 17/218 [00:14<03:09,  1.06it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 18/218 [00:15<03:01,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▊         | 19/218 [00:16<02:35,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▉         | 20/218 [00:16<02:11,  1.51it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|▉         | 21/218 [00:19<04:39,  1.42s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|█         | 22/218 [00:20<04:03,  1.24s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 23/218 [00:20<03:05,  1.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 24/218 [00:21<02:35,  1.25it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█▏        | 25/218 [00:21<02:02,  1.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 26/218 [00:22<01:49,  1.75it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 27/218 [00:22<01:34,  2.01it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 28/218 [00:23<01:45,  1.80it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 29/218 [00:24<02:30,  1.25it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 30/218 [00:25<02:34,  1.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 31/218 [00:25<02:02,  1.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▍        | 32/218 [00:25<01:37,  1.90it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▌        | 33/218 [00:31<06:28,  2.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 34/218 [00:36<09:07,  2.98s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 35/218 [00:43<12:36,  4.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 36/218 [00:44<09:47,  3.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 37/218 [00:49<11:06,  3.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 38/218 [00:53<11:16,  3.76s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 39/218 [00:53<08:06,  2.72s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 40/218 [00:53<06:00,  2.02s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 41/218 [00:54<04:30,  1.53s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 42/218 [00:54<03:26,  1.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|█▉        | 43/218 [00:55<02:45,  1.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|██        | 44/218 [00:55<02:17,  1.26it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 45/218 [00:58<04:01,  1.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 46/218 [01:24<25:10,  8.78s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 47/218 [01:24<17:56,  6.29s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 48/218 [01:25<13:11,  4.66s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 49/218 [01:25<09:24,  3.34s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 50/218 [01:27<07:42,  2.76s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 51/218 [01:27<05:41,  2.04s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 52/218 [01:27<04:13,  1.53s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 53/218 [01:28<03:13,  1.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▍       | 54/218 [01:28<02:25,  1.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▌       | 55/218 [01:28<01:57,  1.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 56/218 [01:29<01:54,  1.41it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 57/218 [01:30<01:50,  1.46it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 58/218 [01:30<01:49,  1.47it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 59/218 [01:31<01:29,  1.78it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 60/218 [01:31<01:27,  1.80it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 61/218 [01:32<01:16,  2.06it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 62/218 [01:32<01:08,  2.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 63/218 [01:32<01:02,  2.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 64/218 [01:32<00:58,  2.64it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|██▉       | 65/218 [01:33<01:01,  2.51it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|███       | 66/218 [01:33<01:00,  2.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 67/218 [01:34<00:56,  2.66it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 68/218 [01:34<00:54,  2.77it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 69/218 [01:34<00:47,  3.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 70/218 [01:35<01:19,  1.87it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 71/218 [01:36<01:07,  2.18it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 72/218 [01:36<01:03,  2.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 73/218 [01:36<00:58,  2.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 74/218 [01:37<00:54,  2.63it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 75/218 [01:37<00:54,  2.63it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▍      | 76/218 [01:37<00:54,  2.62it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▌      | 77/218 [01:38<00:55,  2.54it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 78/218 [01:38<00:50,  2.76it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 79/218 [01:38<00:51,  2.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 80/218 [01:39<01:10,  1.97it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 81/218 [01:40<01:00,  2.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 82/218 [01:40<00:53,  2.57it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 83/218 [01:40<00:52,  2.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▊      | 84/218 [01:41<00:51,  2.62it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 85/218 [01:41<00:52,  2.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 86/218 [01:42<00:58,  2.24it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|███▉      | 87/218 [01:42<01:09,  1.90it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|████      | 88/218 [01:43<01:16,  1.69it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████      | 89/218 [01:46<03:08,  1.46s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████▏     | 90/218 [01:51<04:51,  2.28s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 91/218 [01:52<04:10,  1.98s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 92/218 [02:18<19:18,  9.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 93/218 [02:20<14:30,  6.96s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 94/218 [02:21<10:46,  5.21s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▎     | 95/218 [02:21<07:38,  3.73s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 96/218 [02:22<05:34,  2.74s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 97/218 [02:23<04:36,  2.28s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▍     | 98/218 [02:24<03:40,  1.84s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▌     | 99/218 [02:24<02:41,  1.35s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▌     | 100/218 [02:24<02:05,  1.06s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▋     | 101/218 [02:25<01:38,  1.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 102/218 [02:25<01:17,  1.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 103/218 [02:25<01:14,  1.54it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 104/218 [02:27<01:44,  1.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 105/218 [02:32<04:02,  2.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▊     | 106/218 [02:32<02:59,  1.60s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▉     | 107/218 [02:32<02:11,  1.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|████▉     | 108/218 [02:33<01:50,  1.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 109/218 [02:34<01:38,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 110/218 [02:34<01:30,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████     | 111/218 [02:35<01:12,  1.47it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████▏    | 112/218 [02:35<00:57,  1.84it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 113/218 [02:35<00:47,  2.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 114/218 [02:37<01:15,  1.37it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 115/218 [02:37<01:01,  1.68it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 116/218 [02:38<01:13,  1.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▎    | 117/218 [02:38<00:59,  1.70it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▍    | 118/218 [02:38<00:48,  2.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▍    | 119/218 [02:39<00:50,  1.95it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▌    | 120/218 [02:40<00:53,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 121/218 [02:40<00:44,  2.16it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 122/218 [02:41<01:11,  1.33it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▋    | 123/218 [02:42<01:14,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 124/218 [02:42<00:58,  1.62it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 125/218 [02:43<00:46,  1.99it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 126/218 [02:43<00:56,  1.64it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 127/218 [02:45<01:27,  1.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▊    | 128/218 [02:46<01:08,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▉    | 129/218 [02:46<00:53,  1.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|█████▉    | 130/218 [02:46<00:44,  1.96it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|██████    | 131/218 [02:47<00:54,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 132/218 [02:48<00:59,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 133/218 [02:48<00:58,  1.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████▏   | 134/218 [02:53<02:29,  1.78s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 135/218 [02:54<02:09,  1.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 136/218 [02:55<01:51,  1.36s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 137/218 [02:55<01:22,  1.02s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 138/218 [02:55<01:02,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 139/218 [02:55<00:49,  1.59it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 140/218 [02:56<00:40,  1.91it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▍   | 141/218 [02:56<00:34,  2.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▌   | 142/218 [02:56<00:29,  2.62it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 143/218 [02:56<00:25,  2.99it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 144/218 [02:57<00:23,  3.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 145/218 [02:57<00:24,  2.96it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 146/218 [02:57<00:21,  3.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 147/218 [02:58<00:19,  3.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 148/218 [02:58<00:20,  3.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 149/218 [03:00<01:01,  1.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 150/218 [03:01<00:52,  1.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 151/218 [03:10<03:41,  3.31s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|██████▉   | 152/218 [03:11<02:46,  2.52s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|███████   | 153/218 [03:37<10:21,  9.56s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 154/218 [03:37<07:15,  6.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 155/218 [03:40<06:03,  5.76s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 156/218 [03:41<04:17,  4.15s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 157/218 [03:46<04:28,  4.41s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 158/218 [03:50<04:21,  4.36s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 159/218 [03:54<04:06,  4.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 160/218 [03:54<02:56,  3.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 161/218 [03:54<02:07,  2.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 162/218 [03:55<01:32,  1.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▍  | 163/218 [03:57<01:42,  1.85s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▌  | 164/218 [04:01<02:06,  2.34s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 165/218 [04:02<01:45,  1.99s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 166/218 [04:02<01:16,  1.47s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 167/218 [04:07<02:15,  2.66s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 168/218 [04:11<02:32,  3.04s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 169/218 [04:16<02:57,  3.62s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 170/218 [04:22<03:31,  4.40s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 171/218 [04:30<04:05,  5.21s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 172/218 [04:35<04:06,  5.37s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 173/218 [04:42<04:15,  5.68s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|███████▉  | 174/218 [04:50<04:41,  6.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|████████  | 175/218 [04:55<04:22,  6.09s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 176/218 [05:01<04:09,  5.94s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 177/218 [05:07<04:07,  6.04s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 178/218 [05:15<04:28,  6.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 179/218 [05:18<03:32,  5.44s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 180/218 [05:24<03:34,  5.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 181/218 [05:28<03:09,  5.11s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 182/218 [05:29<02:23,  3.98s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 183/218 [05:32<02:12,  3.79s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 184/218 [05:37<02:14,  3.97s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▍ | 185/218 [05:41<02:10,  3.96s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▌ | 186/218 [05:49<02:46,  5.21s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 187/218 [05:52<02:23,  4.62s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 188/218 [05:54<01:57,  3.90s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 189/218 [05:55<01:22,  2.83s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 190/218 [05:55<00:57,  2.07s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 191/218 [05:55<00:40,  1.52s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 192/218 [05:55<00:29,  1.15s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▊ | 193/218 [05:56<00:22,  1.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 194/218 [05:56<00:17,  1.40it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 195/218 [05:56<00:13,  1.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|████████▉ | 196/218 [05:57<00:11,  1.98it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|█████████ | 197/218 [05:57<00:10,  2.00it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████ | 198/218 [05:58<00:09,  2.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████▏| 199/218 [06:00<00:17,  1.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 200/218 [06:03<00:30,  1.67s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 201/218 [06:03<00:21,  1.24s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 202/218 [06:04<00:19,  1.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 203/218 [06:05<00:17,  1.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▎| 204/218 [06:08<00:20,  1.47s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 205/218 [06:10<00:22,  1.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 206/218 [06:10<00:16,  1.34s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▍| 207/218 [06:14<00:21,  1.97s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▌| 208/218 [06:14<00:14,  1.48s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▌| 209/218 [06:14<00:09,  1.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▋| 210/218 [06:22<00:24,  3.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 211/218 [06:31<00:34,  4.89s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 212/218 [06:57<01:07, 11.27s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 213/218 [07:20<01:12, 14.60s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 214/218 [07:30<00:52, 13.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▊| 215/218 [07:46<00:42, 14.06s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▉| 216/218 [08:11<00:34, 17.38s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|█████████▉| 217/218 [08:19<00:14, 14.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|██████████| 218/218 [08:31<00:00, 13.83s/it]generating response: 100%|██████████| 218/218 [08:31<00:00,  2.35s/it]
generation part takes 531.07s
Full generation completed in 2521.99s
/home/xuyue/miniconda3/envs/llava/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/xuyue/miniconda3/envs/llava/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
processed 218 images, 218 texts in 0.07s
using blip for generation
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:07<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]
generating response:   0%|          | 0/218 [00:00<?, ?it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   0%|          | 1/218 [00:01<05:57,  1.65s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|          | 2/218 [00:01<03:08,  1.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|▏         | 3/218 [00:02<02:19,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 4/218 [00:02<02:08,  1.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 5/218 [00:03<02:02,  1.74it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 6/218 [00:04<02:05,  1.69it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 7/218 [00:04<01:43,  2.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▎         | 8/218 [00:06<03:10,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▍         | 9/218 [00:07<03:11,  1.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▍         | 10/218 [00:07<02:42,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▌         | 11/218 [00:08<03:21,  1.03it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 12/218 [00:09<02:49,  1.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 13/218 [00:10<03:12,  1.06it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▋         | 14/218 [00:11<02:43,  1.25it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 15/218 [00:11<02:22,  1.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 16/218 [00:12<02:44,  1.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 17/218 [00:13<02:47,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 18/218 [00:14<02:46,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▊         | 19/218 [00:14<02:24,  1.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▉         | 20/218 [00:15<02:03,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|▉         | 21/218 [00:18<04:28,  1.37s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|█         | 22/218 [00:18<03:42,  1.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 23/218 [00:19<03:09,  1.03it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 24/218 [00:19<02:38,  1.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█▏        | 25/218 [00:20<02:04,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 26/218 [00:20<01:48,  1.76it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 27/218 [00:20<01:34,  2.01it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 28/218 [00:21<01:42,  1.85it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 29/218 [00:22<02:30,  1.26it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 30/218 [00:23<02:34,  1.22it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 31/218 [00:24<02:02,  1.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▍        | 32/218 [00:24<01:38,  1.90it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▌        | 33/218 [00:30<06:29,  2.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 34/218 [00:34<08:29,  2.77s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 35/218 [00:40<11:50,  3.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 36/218 [00:42<09:15,  3.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 37/218 [00:46<10:45,  3.56s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 38/218 [00:47<07:46,  2.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 39/218 [00:47<05:39,  1.90s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 40/218 [00:47<04:18,  1.45s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 41/218 [00:48<03:19,  1.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 42/218 [00:48<02:36,  1.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|█▉        | 43/218 [00:48<02:11,  1.33it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|██        | 44/218 [00:49<02:09,  1.35it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 45/218 [00:50<01:49,  1.57it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 46/218 [01:16<23:39,  8.25s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 47/218 [01:16<16:53,  5.93s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 48/218 [01:17<12:27,  4.40s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 49/218 [01:17<09:08,  3.25s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 50/218 [01:19<07:31,  2.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 51/218 [01:19<05:33,  1.99s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 52/218 [01:19<04:05,  1.48s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 53/218 [01:20<03:07,  1.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▍       | 54/218 [01:20<02:21,  1.16it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▌       | 55/218 [01:20<01:54,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 56/218 [01:21<01:52,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 57/218 [01:22<01:48,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 58/218 [01:22<01:48,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 59/218 [01:23<01:28,  1.79it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 60/218 [01:23<01:27,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 61/218 [01:23<01:13,  2.13it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 62/218 [01:24<01:04,  2.41it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 63/218 [01:24<01:00,  2.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 64/218 [01:27<03:00,  1.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|██▉       | 65/218 [01:28<02:25,  1.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|███       | 66/218 [01:28<01:59,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 67/218 [01:28<01:37,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 68/218 [01:29<01:22,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 69/218 [01:29<01:07,  2.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 70/218 [01:30<01:33,  1.59it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 71/218 [01:30<01:16,  1.91it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 72/218 [01:30<01:09,  2.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 73/218 [01:31<01:02,  2.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 74/218 [01:31<00:58,  2.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 75/218 [01:32<00:56,  2.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▍      | 76/218 [01:32<00:55,  2.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▌      | 77/218 [01:32<00:56,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 78/218 [01:33<00:51,  2.72it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 79/218 [01:33<00:52,  2.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 80/218 [01:34<01:06,  2.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 81/218 [01:34<00:57,  2.37it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 82/218 [01:34<00:57,  2.37it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 83/218 [01:35<00:55,  2.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▊      | 84/218 [01:35<00:53,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 85/218 [01:36<00:52,  2.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 86/218 [01:36<00:59,  2.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|███▉      | 87/218 [01:37<01:11,  1.84it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|████      | 88/218 [01:38<01:18,  1.66it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████      | 89/218 [01:39<01:51,  1.16it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████▏     | 90/218 [01:43<03:57,  1.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 91/218 [01:45<03:33,  1.68s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 92/218 [02:11<18:55,  9.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 93/218 [02:12<14:14,  6.84s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 94/218 [02:14<10:35,  5.12s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▎     | 95/218 [02:14<07:33,  3.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 96/218 [02:14<05:30,  2.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 97/218 [02:16<04:34,  2.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▍     | 98/218 [02:16<03:38,  1.82s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▌     | 99/218 [02:17<02:40,  1.34s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▌     | 100/218 [02:17<02:04,  1.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▋     | 101/218 [02:17<01:37,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 102/218 [02:18<01:17,  1.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 103/218 [02:18<01:13,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 104/218 [02:20<01:43,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 105/218 [02:25<04:00,  2.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▊     | 106/218 [02:25<02:58,  1.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▉     | 107/218 [02:25<02:11,  1.18s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|████▉     | 108/218 [02:26<01:50,  1.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 109/218 [02:27<01:38,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 110/218 [02:27<01:16,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████     | 111/218 [02:27<01:03,  1.69it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████▏    | 112/218 [02:28<01:13,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 113/218 [02:28<00:58,  1.80it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 114/218 [02:28<00:47,  2.19it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 115/218 [02:29<00:42,  2.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 116/218 [02:29<00:36,  2.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▎    | 117/218 [02:29<00:33,  3.01it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▍    | 118/218 [02:30<00:30,  3.24it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▍    | 119/218 [02:30<00:38,  2.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▌    | 120/218 [02:31<00:45,  2.17it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 121/218 [02:31<00:39,  2.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 122/218 [02:32<01:07,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▋    | 123/218 [02:33<01:12,  1.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 124/218 [02:34<01:09,  1.35it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 125/218 [02:34<00:54,  1.70it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 126/218 [02:35<01:02,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 127/218 [02:37<01:31,  1.00s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▊    | 128/218 [02:37<01:10,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▉    | 129/218 [02:37<00:55,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|█████▉    | 130/218 [02:38<00:46,  1.89it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|██████    | 131/218 [02:39<00:55,  1.56it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 132/218 [02:39<01:00,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 133/218 [02:40<00:59,  1.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████▏   | 134/218 [02:43<01:58,  1.41s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 135/218 [02:44<01:48,  1.31s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 136/218 [02:45<01:20,  1.01it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 137/218 [02:45<01:03,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 138/218 [02:45<00:49,  1.63it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 139/218 [02:45<00:40,  1.97it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 140/218 [02:46<00:34,  2.24it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▍   | 141/218 [02:46<00:30,  2.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▌   | 142/218 [02:46<00:26,  2.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 143/218 [02:46<00:24,  3.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 144/218 [02:47<00:23,  3.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 145/218 [02:47<00:24,  3.02it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 146/218 [02:47<00:22,  3.25it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 147/218 [02:48<00:20,  3.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 148/218 [02:48<00:21,  3.26it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 149/218 [02:50<01:02,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 150/218 [02:51<00:52,  1.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 151/218 [03:00<03:41,  3.31s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|██████▉   | 152/218 [03:01<02:54,  2.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|███████   | 153/218 [03:27<10:26,  9.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 154/218 [03:27<07:19,  6.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 155/218 [03:28<05:11,  4.94s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 156/218 [03:28<03:41,  3.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 157/218 [03:33<04:04,  4.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 158/218 [03:37<04:00,  4.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 159/218 [03:41<03:52,  3.93s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 160/218 [03:41<02:47,  2.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 161/218 [03:42<02:02,  2.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 162/218 [03:42<01:28,  1.58s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▍  | 163/218 [03:42<01:05,  1.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▌  | 164/218 [03:43<00:49,  1.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 165/218 [03:43<00:38,  1.37it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 166/218 [03:44<00:39,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 167/218 [03:50<02:02,  2.41s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 168/218 [03:50<01:30,  1.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 169/218 [03:57<02:39,  3.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 170/218 [04:05<03:50,  4.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 171/218 [04:12<04:13,  5.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 172/218 [04:13<03:01,  3.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 173/218 [04:20<03:40,  4.89s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|███████▉  | 174/218 [04:28<04:17,  5.84s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|████████  | 175/218 [04:33<04:05,  5.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 176/218 [04:41<04:24,  6.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 177/218 [04:49<04:38,  6.78s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 178/218 [04:55<04:21,  6.54s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 179/218 [05:00<04:00,  6.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 180/218 [05:06<03:53,  6.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 181/218 [05:10<03:22,  5.47s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 182/218 [05:12<02:32,  4.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 183/218 [05:15<02:18,  3.97s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 184/218 [05:18<02:02,  3.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▍ | 185/218 [05:23<02:19,  4.24s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▌ | 186/218 [05:27<02:06,  3.94s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 187/218 [05:31<02:07,  4.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 188/218 [05:33<01:45,  3.53s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 189/218 [05:34<01:14,  2.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 190/218 [05:34<00:52,  1.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 191/218 [05:34<00:37,  1.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 192/218 [05:34<00:27,  1.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▊ | 193/218 [05:35<00:20,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 194/218 [05:35<00:16,  1.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 195/218 [05:35<00:13,  1.76it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|████████▉ | 196/218 [05:36<00:10,  2.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|█████████ | 197/218 [05:36<00:10,  2.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████ | 198/218 [05:36<00:08,  2.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████▏| 199/218 [05:37<00:07,  2.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 200/218 [05:37<00:06,  2.64it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 201/218 [05:38<00:08,  1.95it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 202/218 [05:39<00:10,  1.47it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 203/218 [05:40<00:11,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▎| 204/218 [05:42<00:17,  1.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 205/218 [05:44<00:19,  1.53s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 206/218 [05:45<00:15,  1.33s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▍| 207/218 [05:49<00:21,  1.97s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▌| 208/218 [05:49<00:14,  1.48s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▌| 209/218 [05:49<00:09,  1.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▋| 210/218 [05:57<00:24,  3.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 211/218 [06:06<00:34,  4.89s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 212/218 [06:32<01:07, 11.27s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 213/218 [06:43<00:55, 11.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 214/218 [07:00<00:50, 12.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▊| 215/218 [07:16<00:41, 13.70s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▉| 216/218 [07:36<00:31, 15.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|█████████▉| 217/218 [07:43<00:13, 13.16s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|██████████| 218/218 [07:56<00:00, 13.25s/it]generating response: 100%|██████████| 218/218 [07:56<00:00,  2.19s/it]
generation part takes 496.34s
processed 218 images, 218 texts in 496.44s
using blip for generation
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:07,  2.60s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.08s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.49s/it]
generating response:   0%|          | 0/218 [00:00<?, ?it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   0%|          | 1/218 [00:00<00:50,  4.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|          | 2/218 [00:00<01:01,  3.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|▏         | 3/218 [00:00<01:10,  3.06it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 4/218 [00:01<01:26,  2.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 5/218 [00:01<01:35,  2.24it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 6/218 [00:02<01:47,  1.98it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 7/218 [00:02<01:30,  2.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▎         | 8/218 [00:04<03:02,  1.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▍         | 9/218 [00:05<03:05,  1.13it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▍         | 10/218 [00:06<02:37,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▌         | 11/218 [00:07<03:18,  1.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 12/218 [00:07<02:47,  1.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 13/218 [00:09<03:11,  1.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▋         | 14/218 [00:09<02:42,  1.26it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 15/218 [00:10<02:21,  1.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 16/218 [00:11<02:43,  1.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 17/218 [00:12<02:46,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 18/218 [00:12<02:45,  1.21it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▊         | 19/218 [00:13<02:24,  1.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▉         | 20/218 [00:13<02:03,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|▉         | 21/218 [00:16<04:28,  1.36s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|█         | 22/218 [00:17<03:37,  1.11s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 23/218 [00:17<03:00,  1.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 24/218 [00:18<02:31,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█▏        | 25/218 [00:18<01:59,  1.62it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 26/218 [00:18<01:44,  1.83it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 27/218 [00:19<01:32,  2.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 28/218 [00:19<01:40,  1.89it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 29/218 [00:21<02:27,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 30/218 [00:22<02:32,  1.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 31/218 [00:22<02:00,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▍        | 32/218 [00:22<01:36,  1.92it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▌        | 33/218 [00:28<06:25,  2.09s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 34/218 [00:32<08:24,  2.74s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 35/218 [00:39<11:46,  3.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 36/218 [00:40<09:13,  3.04s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 37/218 [00:44<10:42,  3.55s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 38/218 [00:45<07:44,  2.58s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 39/218 [00:45<05:38,  1.89s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 40/218 [00:46<04:17,  1.45s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 41/218 [00:46<03:19,  1.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 42/218 [00:46<02:36,  1.13it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|█▉        | 43/218 [00:47<02:11,  1.33it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|██        | 44/218 [00:47<02:08,  1.35it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 45/218 [00:48<01:49,  1.57it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 46/218 [01:14<23:38,  8.25s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 47/218 [01:14<16:52,  5.92s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 48/218 [01:15<12:27,  4.40s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 49/218 [01:16<09:08,  3.24s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 50/218 [01:17<07:31,  2.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 51/218 [01:17<05:32,  1.99s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 52/218 [01:18<04:05,  1.48s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 53/218 [01:18<03:07,  1.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▍       | 54/218 [01:18<02:22,  1.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▌       | 55/218 [01:19<01:55,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 56/218 [01:19<01:52,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 57/218 [01:20<01:48,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 58/218 [01:21<01:47,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 59/218 [01:21<01:28,  1.79it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 60/218 [01:21<01:26,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 61/218 [01:22<01:13,  2.13it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 62/218 [01:22<01:04,  2.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 63/218 [01:22<01:00,  2.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 64/218 [01:25<03:00,  1.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|██▉       | 65/218 [01:26<02:25,  1.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|███       | 66/218 [01:26<01:59,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 67/218 [01:26<01:37,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 68/218 [01:27<01:22,  1.81it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 69/218 [01:27<01:07,  2.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 70/218 [01:28<01:32,  1.59it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 71/218 [01:28<01:16,  1.91it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 72/218 [01:29<01:09,  2.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 73/218 [01:29<01:02,  2.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 74/218 [01:29<00:57,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 75/218 [01:30<00:56,  2.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▍      | 76/218 [01:30<00:55,  2.56it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▌      | 77/218 [01:31<00:56,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 78/218 [01:31<00:51,  2.73it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 79/218 [01:31<00:52,  2.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 80/218 [01:32<01:06,  2.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 81/218 [01:32<00:57,  2.36it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 82/218 [01:33<00:57,  2.35it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 83/218 [01:33<00:55,  2.41it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▊      | 84/218 [01:33<00:54,  2.46it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 85/218 [01:34<00:53,  2.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 86/218 [01:34<01:00,  2.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|███▉      | 87/218 [01:35<01:11,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|████      | 88/218 [01:36<01:18,  1.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████      | 89/218 [01:37<01:51,  1.16it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████▏     | 90/218 [01:42<03:58,  1.87s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 91/218 [01:43<03:34,  1.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 92/218 [02:09<18:53,  8.99s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 93/218 [02:11<14:13,  6.83s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 94/218 [02:12<10:34,  5.12s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▎     | 95/218 [02:12<07:32,  3.68s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 96/218 [02:13<05:30,  2.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 97/218 [02:14<04:33,  2.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▍     | 98/218 [02:15<03:38,  1.82s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▌     | 99/218 [02:15<02:39,  1.34s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▌     | 100/218 [02:15<02:04,  1.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▋     | 101/218 [02:15<01:37,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 102/218 [02:16<01:17,  1.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 103/218 [02:16<01:14,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 104/218 [02:18<01:43,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 105/218 [02:23<04:00,  2.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▊     | 106/218 [02:23<02:57,  1.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▉     | 107/218 [02:23<02:11,  1.18s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|████▉     | 108/218 [02:24<01:50,  1.00s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 109/218 [02:25<01:38,  1.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 110/218 [02:25<01:15,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████     | 111/218 [02:25<01:02,  1.71it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████▏    | 112/218 [02:26<01:13,  1.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 113/218 [02:26<00:57,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 114/218 [02:27<00:47,  2.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 115/218 [02:27<00:41,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 116/218 [02:27<00:35,  2.86it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▎    | 117/218 [02:27<00:33,  3.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▍    | 118/218 [02:28<00:30,  3.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▍    | 119/218 [02:28<00:38,  2.57it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▌    | 120/218 [02:29<00:44,  2.18it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 121/218 [02:29<00:38,  2.51it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 122/218 [02:31<01:07,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▋    | 123/218 [02:31<01:12,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 124/218 [02:32<01:09,  1.36it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 125/218 [02:32<00:54,  1.71it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 126/218 [02:33<01:01,  1.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 127/218 [02:35<01:31,  1.00s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▊    | 128/218 [02:35<01:10,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▉    | 129/218 [02:35<00:55,  1.62it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|█████▉    | 130/218 [02:36<00:46,  1.90it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|██████    | 131/218 [02:37<00:55,  1.57it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 132/218 [02:38<01:00,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 133/218 [02:38<00:58,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████▏   | 134/218 [02:41<01:57,  1.40s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 135/218 [02:42<01:47,  1.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 136/218 [02:43<01:20,  1.02it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 137/218 [02:43<01:02,  1.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 138/218 [02:43<00:48,  1.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 139/218 [02:43<00:39,  2.00it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 140/218 [02:44<00:34,  2.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▍   | 141/218 [02:44<00:30,  2.52it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▌   | 142/218 [02:44<00:26,  2.85it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 143/218 [02:44<00:23,  3.14it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 144/218 [02:45<00:23,  3.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 145/218 [02:45<00:24,  3.02it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 146/218 [02:45<00:22,  3.26it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 147/218 [02:46<00:20,  3.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 148/218 [02:46<00:21,  3.25it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 149/218 [02:48<01:02,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 150/218 [02:49<00:52,  1.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 151/218 [02:58<03:41,  3.31s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|██████▉   | 152/218 [02:59<02:54,  2.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|███████   | 153/218 [03:25<10:26,  9.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 154/218 [03:25<07:19,  6.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 155/218 [03:26<05:11,  4.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 156/218 [03:26<03:41,  3.58s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 157/218 [03:31<04:04,  4.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 158/218 [03:35<04:01,  4.02s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 159/218 [03:39<03:52,  3.94s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 160/218 [03:39<02:47,  2.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 161/218 [03:40<02:02,  2.15s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 162/218 [03:40<01:28,  1.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▍  | 163/218 [03:40<01:05,  1.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▌  | 164/218 [03:41<00:49,  1.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 165/218 [03:41<00:38,  1.37it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 166/218 [03:42<00:39,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 167/218 [03:48<02:02,  2.41s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 168/218 [03:48<01:30,  1.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 169/218 [03:55<02:39,  3.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 170/218 [04:04<03:50,  4.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 171/218 [04:10<04:13,  5.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 172/218 [04:11<03:01,  3.96s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 173/218 [04:18<03:40,  4.89s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|███████▉  | 174/218 [04:26<04:17,  5.84s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|████████  | 175/218 [04:31<04:05,  5.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 176/218 [04:39<04:24,  6.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 177/218 [04:47<04:38,  6.79s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 178/218 [04:53<04:21,  6.54s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 179/218 [04:58<04:00,  6.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 180/218 [05:04<03:53,  6.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 181/218 [05:08<03:22,  5.47s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 182/218 [05:10<02:32,  4.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 183/218 [05:13<02:18,  3.97s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 184/218 [05:16<02:02,  3.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▍ | 185/218 [05:21<02:19,  4.24s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▌ | 186/218 [05:25<02:06,  3.94s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 187/218 [05:29<02:07,  4.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 188/218 [05:31<01:45,  3.53s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 189/218 [05:32<01:14,  2.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 190/218 [05:32<00:52,  1.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 191/218 [05:32<00:37,  1.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 192/218 [05:32<00:27,  1.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▊ | 193/218 [05:33<00:20,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 194/218 [05:33<00:16,  1.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 195/218 [05:33<00:13,  1.76it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|████████▉ | 196/218 [05:34<00:10,  2.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|█████████ | 197/218 [05:34<00:10,  2.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████ | 198/218 [05:35<00:08,  2.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████▏| 199/218 [05:35<00:07,  2.66it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 200/218 [05:35<00:06,  2.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 201/218 [05:36<00:08,  1.96it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 202/218 [05:37<00:10,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 203/218 [05:38<00:11,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▎| 204/218 [05:40<00:17,  1.22s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 205/218 [05:43<00:19,  1.52s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 206/218 [05:43<00:15,  1.32s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▍| 207/218 [05:47<00:21,  1.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▌| 208/218 [05:47<00:14,  1.47s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▌| 209/218 [05:47<00:09,  1.09s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▋| 210/218 [05:55<00:24,  3.04s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 211/218 [06:04<00:34,  4.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 212/218 [06:30<01:07, 11.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 213/218 [06:41<00:55, 11.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 214/218 [06:57<00:50, 12.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▊| 215/218 [07:13<00:41, 13.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▉| 216/218 [07:33<00:31, 15.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|█████████▉| 217/218 [07:41<00:13, 13.08s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|██████████| 218/218 [07:52<00:00, 12.63s/it]generating response: 100%|██████████| 218/218 [07:52<00:00,  2.17s/it]
generation part takes 487.50s
processed 218 images, 218 texts in 983.98s
using blip for generation
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.43s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.24s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]
generating response:   0%|          | 0/218 [00:00<?, ?it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   0%|          | 1/218 [00:00<00:51,  4.24it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|          | 2/218 [00:00<01:02,  3.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   1%|▏         | 3/218 [00:00<01:10,  3.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 4/218 [00:01<01:26,  2.47it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   2%|▏         | 5/218 [00:01<01:35,  2.24it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 6/218 [00:02<01:47,  1.97it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   3%|▎         | 7/218 [00:02<01:31,  2.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▎         | 8/218 [00:04<03:02,  1.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   4%|▍         | 9/218 [00:05<03:06,  1.12it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▍         | 10/218 [00:06<02:38,  1.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   5%|▌         | 11/218 [00:07<03:18,  1.04it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 12/218 [00:07<02:47,  1.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▌         | 13/218 [00:09<03:11,  1.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   6%|▋         | 14/218 [00:09<02:42,  1.26it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 15/218 [00:10<02:21,  1.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   7%|▋         | 16/218 [00:11<02:43,  1.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 17/218 [00:12<02:47,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   8%|▊         | 18/218 [00:12<02:46,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▊         | 19/218 [00:13<02:24,  1.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:   9%|▉         | 20/218 [00:13<02:03,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|▉         | 21/218 [00:16<04:28,  1.36s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  10%|█         | 22/218 [00:17<03:38,  1.12s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 23/218 [00:17<03:02,  1.07it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█         | 24/218 [00:18<02:32,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  11%|█▏        | 25/218 [00:18<01:59,  1.61it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 26/218 [00:18<01:45,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  12%|█▏        | 27/218 [00:19<01:32,  2.06it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 28/218 [00:19<01:40,  1.88it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  13%|█▎        | 29/218 [00:21<02:28,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 30/218 [00:22<02:33,  1.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  14%|█▍        | 31/218 [00:22<02:00,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▍        | 32/218 [00:22<01:36,  1.92it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  15%|█▌        | 33/218 [00:28<06:26,  2.09s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 34/218 [00:32<08:25,  2.75s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  16%|█▌        | 35/218 [00:39<11:47,  3.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 36/218 [00:40<09:13,  3.04s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 37/218 [00:45<10:43,  3.55s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  17%|█▋        | 38/218 [00:45<07:45,  2.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 39/218 [00:45<05:38,  1.89s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  18%|█▊        | 40/218 [00:46<04:17,  1.45s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 41/218 [00:46<03:19,  1.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  19%|█▉        | 42/218 [00:46<02:36,  1.13it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|█▉        | 43/218 [00:47<02:11,  1.33it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  20%|██        | 44/218 [00:47<02:08,  1.35it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 45/218 [00:48<01:50,  1.57it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  21%|██        | 46/218 [01:14<23:39,  8.25s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 47/218 [01:14<16:53,  5.93s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 48/218 [01:15<12:27,  4.40s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  22%|██▏       | 49/218 [01:16<09:08,  3.25s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 50/218 [01:17<07:31,  2.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  23%|██▎       | 51/218 [01:18<05:33,  1.99s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 52/218 [01:18<04:05,  1.48s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  24%|██▍       | 53/218 [01:18<03:07,  1.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▍       | 54/218 [01:18<02:22,  1.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  25%|██▌       | 55/218 [01:19<01:54,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 56/218 [01:19<01:52,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  26%|██▌       | 57/218 [01:20<01:48,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 58/218 [01:21<01:47,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  27%|██▋       | 59/218 [01:21<01:28,  1.79it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 60/218 [01:21<01:26,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 61/218 [01:22<01:13,  2.13it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  28%|██▊       | 62/218 [01:22<01:04,  2.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 63/218 [01:22<01:00,  2.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  29%|██▉       | 64/218 [01:25<03:00,  1.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|██▉       | 65/218 [01:26<02:25,  1.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  30%|███       | 66/218 [01:26<01:58,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 67/218 [01:27<01:37,  1.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  31%|███       | 68/218 [01:27<01:22,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 69/218 [01:27<01:07,  2.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  32%|███▏      | 70/218 [01:28<01:32,  1.59it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 71/218 [01:28<01:16,  1.91it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 72/218 [01:29<01:09,  2.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  33%|███▎      | 73/218 [01:29<01:02,  2.31it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 74/218 [01:29<00:57,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  34%|███▍      | 75/218 [01:30<00:56,  2.54it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▍      | 76/218 [01:30<00:55,  2.55it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  35%|███▌      | 77/218 [01:31<00:56,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 78/218 [01:31<00:51,  2.73it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  36%|███▌      | 79/218 [01:31<00:52,  2.66it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 80/218 [01:32<01:06,  2.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  37%|███▋      | 81/218 [01:32<00:57,  2.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 82/218 [01:33<00:57,  2.37it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  38%|███▊      | 83/218 [01:33<00:55,  2.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▊      | 84/218 [01:33<00:53,  2.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 85/218 [01:34<00:52,  2.54it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  39%|███▉      | 86/218 [01:34<00:59,  2.23it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|███▉      | 87/218 [01:35<01:10,  1.85it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  40%|████      | 88/218 [01:36<01:18,  1.66it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████      | 89/218 [01:37<01:50,  1.16it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  41%|████▏     | 90/218 [01:42<03:57,  1.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 91/218 [01:43<03:33,  1.68s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  42%|████▏     | 92/218 [02:09<18:51,  8.98s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 93/218 [02:11<14:12,  6.82s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  43%|████▎     | 94/218 [02:12<10:33,  5.11s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▎     | 95/218 [02:12<07:32,  3.68s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 96/218 [02:13<05:29,  2.70s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  44%|████▍     | 97/218 [02:14<04:33,  2.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▍     | 98/218 [02:15<03:38,  1.82s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  45%|████▌     | 99/218 [02:15<02:39,  1.34s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▌     | 100/218 [02:15<02:04,  1.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  46%|████▋     | 101/218 [02:15<01:37,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 102/218 [02:16<01:17,  1.50it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  47%|████▋     | 103/218 [02:16<01:13,  1.56it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 104/218 [02:18<01:43,  1.10it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  48%|████▊     | 105/218 [02:23<04:00,  2.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▊     | 106/218 [02:23<02:57,  1.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  49%|████▉     | 107/218 [02:23<02:11,  1.18s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|████▉     | 108/218 [02:24<01:50,  1.00s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 109/218 [02:25<01:38,  1.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  50%|█████     | 110/218 [02:25<01:15,  1.42it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████     | 111/218 [02:25<01:02,  1.71it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  51%|█████▏    | 112/218 [02:26<01:13,  1.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 113/218 [02:26<00:57,  1.82it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  52%|█████▏    | 114/218 [02:27<00:47,  2.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 115/218 [02:27<00:41,  2.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  53%|█████▎    | 116/218 [02:27<00:35,  2.87it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▎    | 117/218 [02:27<00:33,  3.06it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  54%|█████▍    | 118/218 [02:28<00:30,  3.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▍    | 119/218 [02:28<00:38,  2.58it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  55%|█████▌    | 120/218 [02:29<00:44,  2.18it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 121/218 [02:29<00:38,  2.52it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▌    | 122/218 [02:30<01:07,  1.43it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  56%|█████▋    | 123/218 [02:31<01:11,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 124/218 [02:32<01:08,  1.36it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  57%|█████▋    | 125/218 [02:32<00:54,  1.72it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 126/218 [02:33<01:01,  1.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  58%|█████▊    | 127/218 [02:35<01:30,  1.00it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▊    | 128/218 [02:35<01:10,  1.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  59%|█████▉    | 129/218 [02:35<00:54,  1.62it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|█████▉    | 130/218 [02:36<00:46,  1.91it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  60%|██████    | 131/218 [02:37<00:54,  1.59it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 132/218 [02:37<00:59,  1.44it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████    | 133/218 [02:38<00:58,  1.45it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  61%|██████▏   | 134/218 [02:41<01:57,  1.40s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 135/218 [02:42<01:47,  1.30s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  62%|██████▏   | 136/218 [02:42<01:20,  1.02it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 137/218 [02:43<01:02,  1.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  63%|██████▎   | 138/218 [02:43<00:48,  1.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 139/218 [02:43<00:39,  2.00it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  64%|██████▍   | 140/218 [02:44<00:34,  2.27it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▍   | 141/218 [02:44<00:30,  2.53it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  65%|██████▌   | 142/218 [02:44<00:26,  2.86it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 143/218 [02:44<00:23,  3.15it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  66%|██████▌   | 144/218 [02:45<00:23,  3.13it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 145/218 [02:45<00:23,  3.05it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 146/218 [02:45<00:21,  3.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  67%|██████▋   | 147/218 [02:45<00:20,  3.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 148/218 [02:46<00:21,  3.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  68%|██████▊   | 149/218 [02:48<01:02,  1.11it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 150/218 [02:49<00:52,  1.29it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  69%|██████▉   | 151/218 [02:58<03:41,  3.31s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|██████▉   | 152/218 [02:59<02:53,  2.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  70%|███████   | 153/218 [03:25<10:26,  9.64s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 154/218 [03:25<07:19,  6.86s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  71%|███████   | 155/218 [03:26<05:11,  4.94s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 156/218 [03:26<03:41,  3.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 157/218 [03:31<04:04,  4.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  72%|███████▏  | 158/218 [03:35<04:00,  4.01s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 159/218 [03:39<03:51,  3.93s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  73%|███████▎  | 160/218 [03:39<02:47,  2.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 161/218 [03:40<02:02,  2.14s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  74%|███████▍  | 162/218 [03:40<01:28,  1.58s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▍  | 163/218 [03:40<01:05,  1.19s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  75%|███████▌  | 164/218 [03:41<00:49,  1.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 165/218 [03:41<00:38,  1.38it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  76%|███████▌  | 166/218 [03:42<00:39,  1.32it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 167/218 [03:48<02:02,  2.41s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  77%|███████▋  | 168/218 [03:48<01:29,  1.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 169/218 [03:55<02:39,  3.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 170/218 [04:03<03:50,  4.79s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  78%|███████▊  | 171/218 [04:10<04:13,  5.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 172/218 [04:11<03:01,  3.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  79%|███████▉  | 173/218 [04:18<03:39,  4.89s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|███████▉  | 174/218 [04:26<04:16,  5.84s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  80%|████████  | 175/218 [04:31<04:06,  5.73s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 176/218 [04:39<04:25,  6.31s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  81%|████████  | 177/218 [04:47<04:38,  6.80s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 178/218 [04:53<04:21,  6.55s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  82%|████████▏ | 179/218 [04:58<04:00,  6.17s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 180/218 [05:04<03:53,  6.15s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 181/218 [05:08<03:22,  5.47s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  83%|████████▎ | 182/218 [05:10<02:32,  4.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 183/218 [05:13<02:18,  3.97s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  84%|████████▍ | 184/218 [05:16<02:02,  3.59s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▍ | 185/218 [05:21<02:19,  4.23s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  85%|████████▌ | 186/218 [05:25<02:05,  3.94s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 187/218 [05:29<02:07,  4.10s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  86%|████████▌ | 188/218 [05:31<01:45,  3.53s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 189/218 [05:32<01:14,  2.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  87%|████████▋ | 190/218 [05:32<00:52,  1.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 191/218 [05:32<00:37,  1.39s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  88%|████████▊ | 192/218 [05:32<00:27,  1.05s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▊ | 193/218 [05:33<00:20,  1.20it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 194/218 [05:33<00:16,  1.49it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  89%|████████▉ | 195/218 [05:33<00:13,  1.76it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|████████▉ | 196/218 [05:34<00:10,  2.08it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  90%|█████████ | 197/218 [05:34<00:10,  2.09it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████ | 198/218 [05:34<00:08,  2.30it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  91%|█████████▏| 199/218 [05:35<00:07,  2.67it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 200/218 [05:35<00:06,  2.65it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  92%|█████████▏| 201/218 [05:36<00:08,  1.96it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 202/218 [05:37<00:10,  1.48it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  93%|█████████▎| 203/218 [05:38<00:11,  1.28it/s]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▎| 204/218 [05:40<00:17,  1.22s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 205/218 [05:42<00:19,  1.51s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  94%|█████████▍| 206/218 [05:43<00:15,  1.32s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▍| 207/218 [05:47<00:21,  1.95s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  95%|█████████▌| 208/218 [05:47<00:14,  1.47s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▌| 209/218 [05:47<00:09,  1.09s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  96%|█████████▋| 210/218 [05:55<00:24,  3.03s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 211/218 [06:04<00:34,  4.88s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  97%|█████████▋| 212/218 [06:30<01:07, 11.26s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 213/218 [06:41<00:55, 11.13s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  98%|█████████▊| 214/218 [06:57<00:50, 12.71s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▊| 215/218 [07:13<00:41, 13.69s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response:  99%|█████████▉| 216/218 [07:33<00:31, 15.57s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|█████████▉| 217/218 [07:41<00:13, 13.08s/it]Both `max_new_tokens` (=512) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
generating response: 100%|██████████| 218/218 [07:52<00:00, 12.63s/it]generating response: 100%|██████████| 218/218 [07:52<00:00,  2.17s/it]
generation part takes 483.07s
Full generation completed in 1467.07s
/home/xuyue/miniconda3/envs/llava/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/xuyue/miniconda3/envs/llava/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
processing images... denoise batch:   0%|          | 0/5 [00:00<?, ?it/s]denoise batch:  20%|██        | 1/5 [00:43<02:55, 43.96s/it]denoise batch:  40%|████      | 2/5 [01:28<02:12, 44.03s/it]denoise batch:  60%|██████    | 3/5 [02:11<01:27, 44.00s/it]denoise batch:  80%|████████  | 4/5 [02:55<00:43, 43.95s/it]denoise batch: 100%|██████████| 5/5 [03:05<00:00, 31.61s/it]denoise batch: 100%|██████████| 5/5 [03:05<00:00, 37.12s/it]
/home/xuyue/.local/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
Done
computing cossim... Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.35it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  4.18it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  5.02it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.63it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
/home/xuyue/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:494: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pas_token_id` explicitly by `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation, and ensure your `input_ids` input does not have negative values.
  warnings.warn(
csv file saved at: ./temp_minigpt4
Done
Defender initialized with threshold=-0.003936767578125
processed 218 images, 218 texts in 315.77s
using minigpt4 for generation
Loading MiniGPT-4 models...Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:46<00:46, 46.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.53s/it]
/home/xuyue/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading Q-Former
Loading Q-Former Done
Load MiniGPT-4 Checkpoint: /home/xuyue/QXYtemp/MLM/minigpt4/prerained_minigpt4_7b.pth
Done
generating response:   0%|          | 0/218 [00:00<?, ?it/s]generating response:   0%|          | 0/218 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/xuyue/QXYtemp/MLM/./main.py", line 102, in <module>
    responses = get_response(args.model, texts, images, a=a)
  File "/home/xuyue/QXYtemp/MLM/model_tools.py", line 338, in get_response
    answers.append(query_minigpt(
  File "/home/xuyue/QXYtemp/MLM/model_tools.py", line 441, in query_minigpt
    llm_message, chat_state, img_list = answer(chat,chat_state, img_list)
  File "/home/xuyue/QXYtemp/MLM/model_tools.py", line 427, in answer
    llm_message  = chat.answer(conv=chat_state,
  File "/home/xuyue/QXYtemp/MLM/minigpt4/conversation/conversation.py", line 187, in answer
    output_token = self.model_generate(**generation_dict)[0]
  File "/home/xuyue/QXYtemp/MLM/minigpt4/conversation/conversation.py", line 207, in model_generate
    output = self.model.llama_model.generate(*args, **kwargs)
  File "/home/xuyue/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/xuyue/.local/lib/python3.10/site-packages/transformers/generation/utils.py", line 1758, in generate
    result = self._sample(
  File "/home/xuyue/.local/lib/python3.10/site-packages/transformers/generation/utils.py", line 2397, in _sample
    outputs = self(
  File "/home/xuyue/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/xuyue/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/xuyue/.local/lib/python3.10/site-packages/accelerate/hooks.py", line 166, in new_forward
    output = module._old_forward(*args, **kwargs)
TypeError: LlamaForCausalLM.forward() got an unexpected keyword argument 'cache_position'
